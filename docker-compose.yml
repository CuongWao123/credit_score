



services : 
  # =======================
  # PostgreSQL & pgAdmin
  # =======================
  postgres:
    image: postgres:15
    container_name: data_source_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    command: >
      postgres
      -c wal_level=logical
      -c max_wal_senders=10
      -c max_replication_slots=10
    volumes:
      - ./data/pgdata:/var/lib/postgresql/data
      - ./raw_data:/data
    ports:
      - "5432:5432"

  pgadmin:
    image: dpage/pgadmin4
    container_name: data_source_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
    volumes:
      - ./data/pgadmin_data:/var/lib/pgadmin
      - ./raw_data:/var/lib/pgadmin/storage/
    ports:
      - "8080:80"
    depends_on:
      - postgres

  bureau-api:
    build:
      context: ./data_source/BureauCredit
      dockerfile: Dockerfile
    container_name: bureau-api
    ports:
      - "6666:6666"
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_NAME=BureauCredit
      - DB_USER=postgres
      - DB_PASSWORD=${POSTGRES_PASSWORD}
    depends_on:
      - postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6666/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # =======================
  # Kafka (KRaft mode)
  # =======================
  controller-1:
    image: apache/kafka:3.7.1
    container_name: controller-1
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: controller
      KAFKA_LISTENERS: CONTROLLER://:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - ./data/kafka/controller-1/meta:/var/lib/kafka/data

  controller-2:
    image: apache/kafka:3.7.1
    container_name: controller-2
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: controller
      KAFKA_LISTENERS: CONTROLLER://:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    volumes:
      - ./data/kafka/controller-2/meta:/var/lib/kafka/data

  broker-1:
    image: apache/kafka:3.7.1
    container_name: broker-1
    ports:
      - 29092:9092
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: broker
      KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-1:19092,PLAINTEXT_HOST://localhost:29092'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    volumes:
      - ./data/kafka/broker-1/data:/var/lib/kafka/data
    depends_on:
      - controller-1
      - controller-2

  broker-2:
    image: apache/kafka:3.7.1
    container_name: broker-2
    ports:
      - 39092:9092
    environment:
      KAFKA_NODE_ID: 4
      KAFKA_PROCESS_ROLES: broker
      KAFKA_LISTENERS: 'PLAINTEXT://:19092,PLAINTEXT_HOST://:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker-2:19092,PLAINTEXT_HOST://localhost:39092'
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@controller-1:9093,2@controller-2:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 2
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    volumes:
      - ./data/kafka/broker-2/data:/var/lib/kafka/data
    depends_on:
      - controller-1
      - controller-2
  # =======================
  # Debezium Kafka Connect
  # =======================
  kafka-connect:
    image: debezium/connect:2.7.3.Final
    container_name: kafka-connect
    depends_on:
      - broker-1
      - broker-2
      - postgres
    ports:
      - "8088:8083"
    environment:
      BOOTSTRAP_SERVERS: broker-1:19092,broker-2:19092
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: _connect-configs
      OFFSET_STORAGE_TOPIC: _connect-offsets
      STATUS_STORAGE_TOPIC: _connect-status
      CONFIG_STORAGE_REPLICATION_FACTOR: 2
      OFFSET_STORAGE_REPLICATION_FACTOR: 2
      STATUS_STORAGE_REPLICATION_FACTOR: 2
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      REST_ADVERTISED_HOST_NAME: kafka-connect


  # =======================
  # Apache Spark Cluster
  # =======================
  # spark-master:
  #   image: apache/spark:3.5.7
  #   container_name: spark-master
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_MASTER_HOST=spark-master
  #     - SPARK_MASTER_PORT=7077
  #     - SPARK_MASTER_WEBUI_PORT=8081
  #     - SPARK_EVENTLOG_ENABLED=true
  #     - SPARK_EVENTLOG_DIR=/opt/spark/spark-events
  #   ports:
  #     - "7077:7077"
  #     - "8081:8081"
  #   command: >
  #     bash -c "/opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.master.*.out"
  #   volumes:
  #     - ./data/spark-events:/opt/spark/spark-events
  #     - ./data/spark-logs:/opt/spark/logs

  # spark-worker-1:
  #   image: apache/spark:3.5.7
  #   container_name: spark-worker-1
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_CORES=2
  #     - SPARK_WORKER_MEMORY=2G
  #   ports:
  #     - "8082:8081"
  #   command: >
  #     bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker.*.out"
  #   volumes:
  #     - ./data/spark-events:/opt/spark/spark-events
  #     - ./data/spark-logs:/opt/spark/logs

  # spark-worker-2:
  #   image: apache/spark:3.5.7
  #   container_name: spark-worker-2
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark-master:7077
  #     - SPARK_WORKER_CORES=2
  #     - SPARK_WORKER_MEMORY=2G
  #   ports:
  #     - "8083:8081"
  #   command: >
  #     bash -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.worker.*.out"
  #   volumes:
  #     - ./data/spark-events:/opt/spark/spark-events
  #     - ./data/spark-logs:/opt/spark/logs

  # spark-history:
  #   image: apache/spark:3.5.7
  #   container_name: spark-history
  #   command: >
  #     bash -c "/opt/spark/sbin/start-history-server.sh && tail -f /opt/spark/logs/spark--org.apache.spark.deploy.history.*.out"
  #   environment:
  #     - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/spark/spark-events
  #   ports:
  #     - "18080:18080"
  #   volumes:
  #     - ./data/spark-events:/opt/spark/spark-events
  #     - ./data/spark-logs:/opt/spark/logs
  
  # # =======================
  # # MINIO Object Storage
  # # =======================
  # minio:
  #   image: "quay.io/minio/minio:RELEASE.2025-03-12T18-04-18Z"
  #   ports:
  #     - "127.0.0.1:9900:9000"
  #     - "127.0.0.1:9901:9001"
  #   command: [ "server", "--console-address", ":9001", "/data" ]
  #   environment:
  #     MINIO_ROOT_USER: ${MINIO_ROOT_USER}
  #     MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}

  # createbuckets:
  #   image: quay.io/minio/mc:RELEASE.2025-03-12T17-29-24Z
  #   depends_on:
  #     - minio
  #   restart: on-failure
  #   entrypoint: >
  #     /bin/sh -c "
  #     sleep 5;
  #     /usr/bin/mc alias set dockerminio http://minio:9000 minioAccessKey minioSecretKey;
  #     /usr/bin/mc mb dockerminio/my-bucket/some-directory;
  #     /usr/bin/mc mb dockerminio/my-other-bucket;
  #     exit 0;
  #     "
  # # =======================
  # # Metabase
  # # =======================
  # metabase:
  #   image: metabase/metabase:v0.56.10.x
  #   container_name: metabase
  #   restart: always
  #   ports:
  #     - "3000:3000"  
  #   environment:
  #     - MB_DB_FILE=/metabase-data/metabase.db
  #   volumes:
  #     - ./data/metabase-data:/metabase-data
